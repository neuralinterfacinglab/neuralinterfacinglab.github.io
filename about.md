---
title: About
permalink: /about/
---

### About us
We are a highly multidisciplinary team interested in developing neural interfaces that measure, decode or stimulate brain activity pattern.


### Research

Our research sits right at the intersection of computer science, neuroscience and clinical applications. We are interested in applying state of the art machine learning techniques to the intricate dynamics of neural data to decode higher-order cogntion. The decoder output is then used to control neuralprostheses, also called Brain-Computer Interfaces, or directly stimulate the brain again. Our research can be divided into two main research lines:

#### invasive Brain-Computer Interfaces
#### PI: Christian Herff
<img width="600" src="{{site.baseurl}}/images/other/a.gif" data-action="zoom">
The invasive Brain-Computer Interface research line investigates closed-loop neural interfaces that process and decode neural activity in real-time to control computer programs and neuroprosthesis and thereby directly provide feedback to the users. To obtain very high quality measures of neural activity, we utilize intracranial recordings in humans. In severe cases of epilepsy, electrodes are implanted to identify the seizure origin. The patients then stay in the epilepsy ward for several weeks and wait to have enough seizures for reliable mapping. This opens a wonderful window of opportunity, as we can record high-fidelity neural signals without putting additional burden on the patients.
Patients greatly enjoy participating in our experiments as they are a welcome relieve from the hospital routine.

One of our focuses is the real-time decoding and synthesis of imagined speech processes.
<img width="600" src="{{site.baseurl}}/images/other/closed-loop_synthesis.png" data-action="zoom">

To bring the field forward, we have shared a large dataset of intracranial EEG during speech production. You can find it [here](https://www.nature.com/articles/s41597-022-01542-9).

Additionally, we also utilize our closed-loop setup to investigate other higher-order cognition, such as **memory**, **navigation** and **decision-making**.
Recently, we have started to investigate low-dimensional representations of neural data to find commonalities across participants.
<img width="600" src="{{site.baseurl}}/images/other/global_motor.jpg" data-action="zoom">

#### adaptive Deep Brain Stimulation
#### PI: Pieter Kubben
<img width="300" src="{{site.baseurl}}/images/other/fig_closed_loop_sq.png" data-action="zoom">
In our adaptive Deep Brain Stimulation (aDBS) research line, we aim to improve DBS by adapting the stimulation to the patients' current state. The patient's current state, including symptome severity and general condition, is thereby inferred using machine learning on wearable sensors. We conduct large scale studies on the home use of wearable sensors in the combination with DBS and app-based evaluation of patient status using the Experience Sampling Methos (ESM).

### Collaborators

Some of the groups we are collaborating with:

**Maastricht University:**
- [Ven Memory and Cognition Group](https://vincentvandeven.weebly.com/)
- [Bettina Sorger's fNIRS BCI group](https://www.maastrichtuniversity.nl/b.sorger)
- [Auditory Cognition Research Group](https://mbic-auditorylab.nl/)

**External:**

- [ASPEN LAB - Virgina Commonwealth University](https://sites.google.com/vcu.edu/aspenlab)
- [Utrecht NeuroProsthesis](https://www.nick-ramsey.eu/)
- [Clinic for Epileptology RWTH Aachen](https://www.ukaachen.de/kliniken-institute/klinik-fuer-neurologie/klinik/sektionen/epileptologie/)
